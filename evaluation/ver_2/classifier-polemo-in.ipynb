{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5470860f-7bb2-4137-88c5-8a7c3440c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9bd21b-3cd1-4c42-b2be-2ec809c00433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# init accelerator\n",
    "# accelerator = Accelerator(device_placement=True, fp16=True, mixed_precision='fp16')\n",
    "# device = accelerator.device\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 8\n",
    "GRAD_ACCUM_STEPS = 32 // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b191eb-9c10-47d7-80af-706ea5c50e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from evaluation.DatasetLoaders import KlejDataset\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "\n",
    "\n",
    "def get_dataloaders(tokenizer, path_train, path_test):\n",
    "    train_set = KlejDataset(path_train, tokenizer, device)\n",
    "    print(train_set.labels_map)\n",
    "    test_set = KlejDataset(path_test, tokenizer, device, train_set.labels_map)\n",
    "    labels = train_set.labels_map\n",
    "    train = DataLoader(dataset=train_set, shuffle=True, batch_size=BATCH_SIZE)\n",
    "    test = DataLoader(dataset=test_set, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "    return train, test, labels\n",
    "\n",
    "dataset_train_path = \"datasets/klej_polemo2.0-in/train.tsv\"\n",
    "dataset_test_path = \"datasets/klej_polemo2.0-in/dev.tsv\"\n",
    "\n",
    "train_loader, test_loader, labels_map = get_dataloaders(tokenizer, dataset_train_path, dataset_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca35985e-9eb5-4461-a6c7-3970a6dcb9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "distil_path = 'weights/plain_distil/2022-06-26_03-19-38/checkpoints/student_orginal_training.pth'\n",
    "\n",
    "from models.klej.bert_polemo import BertPolemo\n",
    "from models.distil_student import creat_student\n",
    "student = creat_student()\n",
    "student.load_state_dict(torch.load(distil_path, map_location=device))\n",
    "\n",
    "student.config.hidden_dropout_prob = 0.2\n",
    "\n",
    "polemo_model = BertPolemo(student.config, len(labels_map))\n",
    "polemo_model.bert.load_state_dict(student.state_dict(), strict=False)\n",
    "polemo_model = polemo_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eef306-c25c-44ee-8405-78cdf18b2660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set accelerator\n",
    "from transformers import AdamW, get_cosine_schedule_with_warmup\n",
    "from trainers.utils import configure_optimizer\n",
    "\n",
    "optim = configure_optimizer(polemo_model, AdamW, weight_decay=1e-3, lr=2e-5)\n",
    "\n",
    "# TU ZMIENIŁEM\n",
    "# train_loader, test_loader, polemo_model, optim = accelerator.prepare(\n",
    "#     train_loader, test_loader, polemo_model, optim)\n",
    "\n",
    "loaders  = {'train': train_loader, 'test': test_loader}\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "scheduler = CosineAnnealingLR(optim, len(train_loader) // GRAD_ACCUM_STEPS * EPOCHS, 0)\n",
    "\n",
    "# NUM_TRAINING_STEPS = len(train_loader) // GRAD_ACCUM_STEPS * EPOCHS\n",
    "# scheduler = get_cosine_schedule_with_warmup(\n",
    "#         optimizer=optim,\n",
    "#         num_cycles=EPOCHS,\n",
    "#         num_warmup_steps=int(0.01 * NUM_TRAINING_STEPS),\n",
    "#         num_training_steps=NUM_TRAINING_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb938c-da5a-4722-93d1-1eddc0deb1a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trainers.vanillaTrainerClassifier import VanillaTrainerClassifier\n",
    "\n",
    "# TU ZMIENIŁEM\n",
    "params_trainer = {\n",
    "    'model': polemo_model.to(device),\n",
    "    'tokenizer': tokenizer,\n",
    "    'loaders': loaders,\n",
    "    'criterion': nn.CrossEntropyLoss().to(device),\n",
    "    'optim': optim,\n",
    "    'scheduler': scheduler,\n",
    "    # 'accelerator': accelerator,\n",
    "    'device': device\n",
    "}\n",
    "trainer = VanillaTrainerClassifier(**params_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c27a1cb-3c29-47d4-8692-cc2241ce8ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4490a14-def6-4df0-bbee-535fd4f6a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "config_run_epoch = collections.namedtuple('RE', ['save_interval', 'grad_accum_steps', 'running_step'])(20, GRAD_ACCUM_STEPS, 40)\n",
    "\n",
    "# TU ZMIENIŁEM\n",
    "params_run = {\n",
    "    'epoch_start': 0,\n",
    "    'epoch_end': EPOCHS,\n",
    "    'exp_name': f'classification_polemo-in',\n",
    "    'config_run_epoch': config_run_epoch,\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "trainer.run_exp(**params_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6249e2fe-f313-41a3-b889-a21f86549fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.n_logger.run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72e17f9-36ad-4916-bb48-01c4dc509a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "student.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521bc493-d21e-40d3-ac88-a4a57ca30a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tldl",
   "language": "python",
   "name": "tldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
