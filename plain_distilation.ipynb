{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5470860f-7bb2-4137-88c5-8a7c3440c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9bd21b-3cd1-4c42-b2be-2ec809c00433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a468a05a-27d7-4067-82f3-1d625ed670ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example dataset\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, sentences_path):\n",
    "        self.sentences = pd.read_csv(sentences_path)['sentence'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = {'sentence': self.sentences[idx]}\n",
    "        return data\n",
    "\n",
    "dataset = CustomImageDataset('datasets/datasetSentences.csv')\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32)\n",
    "loaders  = {'train': dataloader, 'test': dataloader}\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2536c-1ca7-4655-9aac-cb121425b6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_teacher_student_tokenizer\n",
    "teacher, student, tokenizer = get_teacher_student_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb938c-da5a-4722-93d1-1eddc0deb1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distilTrainer import DistilTrainer\n",
    "\n",
    "params_trainer = {\n",
    "    'teacher': teacher.to(device),\n",
    "    'student': student.to(device),\n",
    "    'tokenizer': tokenizer,\n",
    "    'loaders': loaders,\n",
    "    'criterion1': nn.CrossEntropyLoss().to(device),\n",
    "    # 'criterion2': nn.CrossEntropyLoss().to(device),\n",
    "    'criterion2': nn.KLDivLoss('batchmean', log_target=True).to(device), # mam używać log_target?\n",
    "    'criterion3': nn.CosineEmbeddingLoss().to(device),\n",
    "    'optim': torch.optim.AdamW(student.parameters(), lr=1e-3, weight_decay=0.0), # wyrzucić z wd embedingi i batchnormalization\n",
    "    'device': device\n",
    "}\n",
    "trainer = DistilTrainer(**params_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c27a1cb-3c29-47d4-8692-cc2241ce8ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4490a14-def6-4df0-bbee-535fd4f6a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_run = {\n",
    "    'epoch_start': 0,\n",
    "    'epoch_end': 2,\n",
    "    'exp_name': 'plain_distil',\n",
    "    'save_interval': 100,\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "trainer.run_exp(**params_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0955caf-e6ad-4315-98e2-d9d92e2750e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tldl",
   "language": "python",
   "name": "tldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
